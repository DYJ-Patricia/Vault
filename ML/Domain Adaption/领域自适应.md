# Domain Shift
- domain shift: 训练资料和测试资料have different distribution时
- 那么需要domain adaption来解决
- ![[Pasted image 20251026194137.png]]

![[Pasted image 20251026194345.png]]
- Source Domain来自Training Data，Target Domain来自Testing Domain
# Domain Adaption

![[Pasted image 20251026194837.png]]
- 在用带有标签的source domain训练模型后，对于target domain的knowledge有几种情况
- 其中一种，是少量带有标签的数据，用其数据微调模型
- 如果是大量带标签数据就不需要domain adaption了，直接用target domain训练就行
- 接下来讲的是大量无标签target domain
# Large and Labeled
## Basic Idea

- 可以用feature extractor（一种network）分别输入source和target的domain，输出feature
- 并且舍弃不一样的，保留两者相同的feature

![[Pasted image 20251026201322.png]]
- 上面相当于一个image classifier
- source domain 输入，变成vector，然后变成判定答案
- 而target domain输入后，因为是unlabeled，所以只需要将其通过feature extractor之后的输出与source domain通过的输出对比，要分不出差异
- 那怎么才能使红色和蓝色的点分不出差异呢？要用到domain adversarial training的技术

## Domain Adversarial Training

- 训练一个二元domain classifier
- 把通过feature extractor之后的feature都输入后判断其原输入来自哪里
- feature extractor学习的目标就是骗过domain classifier
- 可以把feature extractor看作generator，把domain classifier看作discriminator
- 用source domain的label可以与输出算出entropy loss,记作L
- domain classifier作判断的二元问题也会有一个loss叫L_d
- 各自有相应的θ参数，θp尽量使L最小，θd使L_d最小，θf使（L-L_d）最小
- ![[Pasted image 20251026203356.png]]
## Boundary

![[Pasted image 20251026204135.png]]
- 观察上图，离boundary越来越远地分布貌似更好
- ![[Pasted image 20251026204323.png]]

![[Pasted image 20251026204651.png]]

# Little and Labeled

![[Pasted image 20251026204851.png]]
# Don't know(Domain Generalization)

- 一种为训练资料非常丰富，包含了各种domain
- 另一种为训练资料只有一种domain,而测试资料上却有几种domain:可以找个data augmentation的方法使data变多，然后套上面那种情况的方法就行
- ![[Pasted image 20251026205247.png]]

