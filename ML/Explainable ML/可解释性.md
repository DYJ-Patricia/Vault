- 有些模型内在地具有可解释性，如Linear Model 从weight中可以知道the importance of features,但并不powerful
- Deep network 很强大，但是相当于黑箱，难以解释

# Goal of Explainable ML

- 让人信服


# 分类
共分为两类：Local Explanation,Global Explanation

![[Pasted image 20251024174516.png]]

# Local Explanation(Explain the dicision)

## Which component is critical?

### 最简单的方法（拿方块分别遮挡不同地方）
![[Pasted image 20251024175451.png]]
### Saliency Map

![[Pasted image 20251024175626.png]]
- 先算所有pixel有关的loss
- 选一个pixel做出改动后，再计算loss
- loss变动越大，代表该区域越重要

### 怎么看得更爽
![[Pasted image 20251024180420.png]]
