- 先后学两个任务会遗忘第一个
- 同时学就不会
- Multi-task learning可以看作LLL的upper bound

# 不同评估模型好坏的方法
- ![[Pasted image 20251105233004.png]]

![[Pasted image 20251105233409.png]]
![[Pasted image 20251105233554.png]]

# LLL的三个解法

## Selective Synaptic Plasticity

## Additional Neural Resource Allocation

## Memory Reply
