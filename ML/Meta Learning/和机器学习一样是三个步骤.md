# 机器学习回顾

## Step 1
![[Pasted image 20251107223643.png]]
## Step 2
![[Pasted image 20251107223937.png]]
## Step 3
![[Pasted image 20251107224108.png]]
# Meta Learning

## What is it?

![[Pasted image 20251107224708.png]]
- 和ML类似，Meta Learning也用三个步骤找Learning algorithm
- 一般Function是人造的，但是我们可以通过学习找到它

## Step 1: 决定哪些是Learning algorithm里要学的

![[Pasted image 20251107225045.png]]
- 不同的元学习方法，就对应着不同的需要学习的部分

## Step 2
### 单个任务分析
![[Pasted image 20251107230533.png]]
- 分不同的训练任务，每个任务又有训练资料和测试资料
- 有了这些任务之后，怎么知道algorithm好不好呢

![[Pasted image 20251107230814.png]]
- 找一个任务的训练资料把它放在algorithm里，输出的classifier好，就代表它好，loss低
- 那怎么判断classifier好不好呢？
- 就把这个classifier跑在测试资料上，输出prediction，与答案比较得到 l(上标1)
![[Pasted image 20251107231229.png]]
- l(上标1)计算方法如下：

![[Pasted image 20251107231343.png]]
### 拓展至多个任务

![[Pasted image 20251107231643.png]]
- 把多个任务的loss加起来求平均就是总的Loss

## Step 3

![[Pasted image 20251107232121.png]]
- 解的时候能用微分就用
- 如果解不了就可以用RL硬train


## Framework
![[Pasted image 20251107232612.png]]
- 先用training tasks找出Learning Algorithm
- 再把testing task里的训练资料投进algorithm训练出classifier
- 然后把testing task里的测试资料投进classifier算loss
- testing task里的training data在Meta Learning里是不能碰的

# ML VS Meta

## Goal
![[Pasted image 20251107233234.png]]

## Training Data

![[Pasted image 20251107233359.png]]
- Meta learning 的learning可以叫作Across-task Training
## Learning
![[Pasted image 20251107233549.png]]
## Testing

![[Pasted image 20251107233902.png]]
## Loss

![[Pasted image 20251107233959.png]]
## 跑一个episode才产出一个小l
![[Pasted image 20251107234350.png]]

# 相同点

![[Pasted image 20251107234532.png]]
